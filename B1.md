下面我把你文里“路线 B1（DMPF / Multi‑Point FSS 做核心，再做 Prefix/Aggregate）”按**能直接落你现在这份 repo**的工程形态，展开成一套“接口/Key layout/代码落点/分阶段交付”的设计说明。重点是把现在 SIL1 的：

* **(M−1) 次 DCF 比较 + 每次都带 vector payload + 每层带 vcw**

变成：

* **一次生成：把所有变化点(Δ)编码进一个“稀疏向量”函数分享（DMPF）**
* **一次评估：对这个稀疏向量做一个“suffix/prefix 聚合”直接得到 payload share**

这样 key_bytes 的主项从 `O(M * in_bits * out_words)` 变成 `O(in_bits*λ + M*out_words)`（不再乘起来），这正是你痛点里要干掉的乘法项。

---

## 0) B1 要实现的“真正目标函数”是什么

你现在 SIL1 代码里其实已经写出了 delta 形式（`gen_interval_lut()` 里那段注释和计算就是）：在区间边界 `c_i` 上放 delta，然后根据 `u < c_i` 把 delta 累加/累减得到对应 interval 的 payload。

我们把它写得更清晰一点：

* 有区间 payload：`P[0..M-1]`，每个是 `out_words` 个 `u64`
* 定义 base：`B = P[M-1]`
* 定义 delta：对 `i=0..M-2`，令
  `Δ[i] = P[i] - P[i+1]`（方向你可跟现有实现对齐：也可以用 `P[i+1]-P[i]`，最后公式里符号改一下）

那么对任意 interval index `j`，有：
`P[j] = B + Σ_{i: j ≤ i} Δ[i]`（或等价的另一种索引写法）

在你目前的实现里，`j` 是由 `u_hat` 与 cutpoints 的比较关系决定的。SIL1 做法是对每个 `c_i` 做一遍 `1[u_hat < c_i]`（用 DCF/StepDCF）再乘上 `Δ[i]`。

B1 要做的是：**不再对 i 循环**，而是把所有 `Δ[i]@c_i` 一次性编码进一个“稀疏函数”，然后一次性做聚合拿到：

[
S(u) = \sum_{i=0}^{M-2} \Delta[i]\cdot \mathbf{1}[u < c_i]
]

然后输出就是：

[
\text{out}(u)=B + S(u)
]

（你现有代码是 `B - Σ delta*1[u<c]` 那种写法也行，本质同一件事。）

---

## 1) B1 的核心 primitive：把“变化点”当成一个稀疏向量（DMPF）

把 cutpoints + deltas 看成一个长度 `N=2^{in_bits}` 的稀疏向量函数：

[
h(x)=
\begin{cases}
\Delta[k] & \text{if } x=c_k \
0 & \text{else}
\end{cases}
]

这就是典型 “weight‑t sparse vector” 的分享对象：DPF 是 weight‑1（unit vector），DMPF 是 weight‑t（稀疏向量）。DMPF 这个抽象在文献里就是你提到的路线：很多应用都要从“t 个独立 DPF”升级到真正的 DMPF。IEEE S&P 2025 的那篇就明确说了：大量 use case 里实践上仍是 brute‑force t DPF，他们给出新构造与实现来显著省成本。([Ben-Gurion University Research Portal][1])

所以 B1 的“函数层”目标就是：生成两份 key，使得两方拿着 key、输入公开的 `u_hat`，能得到：
[
S(u)=\sum_{x=u+1}^{N-1} h(x)
]
因为这正是 “所有 cutpoints 在 (u,∞) 的 delta 总和”。

> 直觉上：这一步就是“对稀疏向量做一次 suffix sum（范围求和）”。

---

## 2) 为什么 B1 能把 `in_bits*out_words` 从树上挪走（避免 vcw 每层一份）

你现在 SIL1 的致命项来自：**每层 correction word 里都有一整段 `out_words` 的 vcw**，于是 key bytes 变成 `in_bits*out_words`。

B1 之所以能规避这一点，靠的是你 repo 里其实已经在用、但只用于 bit-output 的那类 DPF 关键性质：

* “每层 correction word 只需要 seed/bits，payload 只在末端出现一次（或只在少数位置出现）”

这在 FSS 的经典 DPF 优化里是明确写出来的：对点函数 DPF，key 的每层 CW(i) 可以只含 seed+少量 bit，额外的 group element（payload）只需要**常数次**出现，而不是每层一次；其 key size 形态就是 `O(n*(λ+常数) + |G|)` 而不是 `O(n*(λ+|G|))`。

把这个思想推广到 DMPF（稀疏多点）时，payload 的花费理想形态变成：

* core（树骨架）：`O(in_bits*λ)`
* payload（变化点）：`O(M*out_words)`（只和变化点个数成正比）
  而不是 `O(in_bits*M*out_words)`。

这就是你在评价里写的 “至少变成 `O(in_bits*λ)+O(M*out_words)`（不乘起来）” 的关键来源。

---

## 3) B1 的“聚合（Prefix/Suffix）”怎么做：用 subtree-sum + dyadic cover 做范围求和

现在剩下一个关键：你有了 `h(x)`（稀疏向量）分享，怎么在 eval 时不枚举点、不枚举 M，就拿到 `Σ_{x>u} h(x)`？

做法是把范围 `(u, N)` 分解成若干棵**完全对齐的子树**（dyadic intervals），然后把每棵子树的“子树总和”加起来。

这个技巧在比较函数（CDPF/DPF 变种）里很常见：**内部节点对应“该子树所有叶子值的和”**，要算一个连续区间的 dot-product，就找能覆盖那段连续 1-block 的最小子树集合，把这些内部节点的值相加。你引用的那段 cdpf.hpp 注释把这点说得很直白：内部节点两方的 share 表示该子树叶子的和，然后用覆盖那段 1-block 的最小节点集合求和即可。([Gogs][2])

对我们这里：

* 连续区间：`[u+1, N-1]`
* 需要的就是：覆盖这个区间的一组 dyadic interval（每个是某个 depth 的某个 prefix 子树）
* 对每个 dyadic interval 节点 v，需要拿到 `sum(v)=Σ_{leaf in subtree(v)} h(leaf)`

如果你的 DMPF 构造支持在 eval 时导出这些内部节点的子树和（这是这类“范围求和/前缀求和”用法的基本能力），那么一次 eval 只需要：

* 按 `in_bits` 深度做固定次数 PRG expand
* 额外累加 O(in_bits) 个子树节点的 `sum(v)`（区间分解最多 ~2*in_bits 个节点）

这满足你对 GPU 的要求：访存/控制流只依赖公开 `u_hat` 和固定 `(in_bits, M_pad, out_words)`，不依赖 secret cutpoints。

---

## 4) 把 B1 落进你 repo：接口、Key layout、代码落点

### 4.1 外部接口保持不变（这点很重要）

你不需要让上层 compiler/IR 认识 DMPF。对上层来说还是：

* `gen_interval_lut(...) -> (key0, key1)`
* `eval_interval_lut_many_device(...) -> out_shares`

区别只是 header version 变了，body 结构变了。

你 repo 里已经有 `SecureIntervalLutHeaderV2` 预留（注释也写了是给 true IntervalLUT 用的）。现在就用它。

### 4.2 SecureIntervalLutHeaderV2：字段怎么用（不改结构也能落地）

你现在 header 是：

```cpp
struct SecureIntervalLutHeaderV2 {
  uint32_t magic;      // currently SIL1
  uint8_t  version;    // currently 1
  uint8_t  in_bits;
  uint8_t  out_bits;
  uint8_t  out_words;
  uint32_t dcf_key_bytes;
  uint32_t bound_bytes;
  uint32_t payload_bytes;
  uint32_t intervals;
  uint32_t reserve;
};
```

B1 的建议解释（只改语义，不必改 struct）：

* `magic`: `'SIL2'`
* `version`: `2`
* `intervals`: 写 **固定的 M_pad**（mask-independent padding 后的值；通常就是编译期选定 M）
* `dcf_key_bytes` → `core_key_bytes`
  （DMPF core：seed/CW 等固定大小部分）
* `payload_bytes` → `aux_bytes`
  （DMPF 需要的额外表/校正/编码块；或者直接叫 payload block bytes）
* `bound_bytes` → 可以保留给 future（比如 dyadic cover 预计算表），第一版先置 0
* `reserve`：塞 flags（dmpf_variant、prg_id、是否启用 SoA layout 等）

### 4.3 Key body（每方一份 blob）的推荐 layout（对齐 GPU）

建议 body 用“对齐 + SoA”的方式，方便 warp 连续读：

```
| SecureIntervalLutHeaderV2 (32B) |
| base_share[out_words]          |  (out_words * 8)
| DMPF_CORE                      |  (core_key_bytes)
| DMPF_AUX/PAYLOAD               |  (payload_bytes)
| padding to 16B                 |
```

**base_share**：保留你现有逻辑（base = last interval payload）。这部分是 per-element 的 out_words*8 字节，无论 SIL1/SIL2 都必须有（除非你把 base 也吸进 DMPF，但没必要）。

`DMPF_CORE` 里放：

* root seed / control bits
* per-level correction seed/bits（固定 `in_bits` 层）
* 任何需要的固定 metadata（例如固定的 hash seeds、bucket params）

`DMPF_AUX/PAYLOAD` 里放：

* 编码后的 “变化点 deltas”（不是明文 `(c_i, Δ_i)` 列表，而是 DMPF 构造所需的编码/校正材料）
* 如果 DMPF 构造需要少量 group-element 校正，也放这里（总量目标是 O(M*out_words) 量级，而非 O(in_bits*M*out_words)）

### 4.4 代码落点（你现在的 repo 结构）

你要改/新增的最关键入口就两处：

1. **Keygen**：`cuda/pfss_backend_gpu.cu`
   现在 SIL1 的 keygen 在 `SecureGpuPfssBackend::gen_interval_lut(...)` 里，生成 `intervals` 个 DCF key。

   B1 版本你要做：

    * `if (header.version == 2) -> gen_interval_lut_sil2_dmpf(...)`
    * 在这里：

        * 计算 `base_share` + `Δ[i]`
        * 调用 DMPF 的 Gen（CPU 先实现 reference）
        * 写入 V2 header + base_share + core + aux

2. **Eval**：`cuda/pfss_backend_gpu.cu` + `cuda/pfss_kernels.cu`
   现在 SIL1 eval kernel 是 `interval_lut_sigma_dcf_kernel_keyed_warp`，里面有 `for b in intervals` 循环。

   B1 版本需要一个新 kernel，形态类似：

    * `interval_lut_sil2_dmpf_suffixsum_kernel<<<...>>>(...)`

   kernel 工作：

    * load header/base_share
    * 读取 `x_hat`（公开）
    * 计算 dyadic cover（最多 ~2*in_bits 个节点）
    * 对每个 cover 节点调用 `dmpf_eval_subtree_sum(...)` 或等价路径
    * sum 得到 `S(u)`
    * out = base_share + S(u)

---

## 5) “dmpf_eval_subtree_sum” 在 GPU 上要长什么样（线程/warp 映射建议）

为了尽量贴你现有的 `*_kernel_keyed_warp` 风格，推荐：

* **warp-per-element**（1 warp 处理 1 个 element）
* lane 0 负责走树、算 cover、产生需要的 node 描述（depth/prefix）
* lane 0 广播 node 描述（`__shfl_sync`）
* 各 lane 并行处理不同 `out_words`：

    * lane `t` 负责 word `t`（或每 lane 负责多个 word）

这样你能得到：

* 访存：core key 按 level 连续读，aux 按固定模式读（不 secret-dependent）
* 计算：PRG expand 的成本被 out_words 并行摊薄
* 最重要：你避免在 kernel 中出现 “按 secret state_id 跳表” 这种 DFA 漏洞路线

---

## 6) 分阶段交付（B1 路线的现实拆分）

你在评价里已经写了 “B1-step1 CPU ref，B1-step2 GPU 小范围，B1-step3 泛化优化”。我建议把它写得更“可落地”一点：

### B1-0：先把“每层 vcw”从单点/单阈值里移走（验证关键收益）

哪怕你还没做多点压缩，先做一个“payload 不再 per-level”的点函数/阈值函数版本，对 key_bytes 的影响非常直观。

理论依据就是你前面提到的那类 DPF 形式：每层 CW 只含 seed/bits，payload 只在末端出现常数次。

在你现 repo 里，bit-DPF 已经基本是这个形态（`dpf_point.hpp` / `dpf_prefix_eval_lt_share_host_` 的思路），所以这是“最小风险”的第一步。

**交付物**：

* 新的 `GroupDPF`（输出 `out_words`）CPU 实现
* 一个 `threshold_eval(u<c)` 能输出 `Δ` 或 0 的 CPU ref（慢没关系）

### B1-1：实现 DMPF core（先不做 suffix 聚合）

目标：给定 t 个点 `(c_i, Δ_i)`，能 eval 得到 `h(x)`（点查询），并且 key size 不再是 t 份 DPF 的简单拼接（至少有明显 amortization）。DMPF 方向本身就是为了摆脱 brute-force 组合。([Ben-Gurion University Research Portal][1])

**交付物**：

* `dmpf_gen(...)` + `dmpf_eval_point(...)` CPU ref
* correctness test：随机稀疏向量（含 padding 到固定 t）

### B1-2：加入 suffix/prefix 聚合（range sum）

目标：实现 `dmpf_eval_range_sum(L,R)` 或直接 `dmpf_eval_suffix(u)`，用 dyadic cover + subtree sum 完成。这里可以借鉴“用内部节点代表子树叶子和、用最小节点集合覆盖一段连续 block 再求和”的套路。([Gogs][2])

**交付物**：

* `dmpf_eval_suffix(u)` CPU ref
* 与 cleartext interval LUT 对齐的单测（你建议的 correctness-first）

### B1-3：GPU kernel（先限形态再泛化）

第一版 GPU 建议**刻意限制**：

* `out_words <= 4` 或 `<=8`
* `in_bits <= 16`/`<=32`
* `M_pad <= 32`（与你现在典型形态一致）

先确保吞吐起来，再泛化。

---

## 7) B1 成本/收益怎么预估（你要的那条“把乘法项拆掉”）

对比现在 SIL1（每 element）近似主项：

* `key_bytes_SIL1 ≈ (M-1) * in_bits * (seed + vcw(out_words))`
* 其中 `vcw(out_words) ~ out_words*8` 是爆炸项

B1 目标主项：

* `key_bytes_B1 ≈ in_bits * seed + M * (out_words*8) + O(M*seed)`
  （最后那项是 DMPF 的多点增量开销，目标别让它回到 `M*in_bits*seed`）

也就是说：**payload 的 out_words 只乘 M，不再乘 in_bits；in_bits 只乘 λ，不再乘 out_words。**

这正是你评价里写的 “至少变成 `O(in_bits*λ)+O(M*out_words)`（不乘起来）”。

---

## 8) 你要特别盯住的两个“落地硬约束”（否则 B1 会变回 SIL1）

1. **eval 不能扫 M 个点**
   只要 eval 里出现 `for i in 0..M-1: compare/accumulate`，你就又回到 “M 次比较” 的世界了，顶多把每次比较 cheaper 一点，但关键路径还是 M。

2. **不能出现 secret-dependent 的 table indexing**
   你在评价里已经指出 DFA/state table 的风险：按 secret state_id 读 global memory 很容易把访问模式变 side-channel。B1 的所有读写必须只依赖：

    * `in_bits, out_words, M_pad`（编译/实例固定）
    * `u_hat`（公开）

   不依赖 `cutpoints` 或任何从 cutpoints 推出来的 secret 分支。

---

如果你后面要我把 **“dyadic cover 的具体实现 + kernel 的 warp 映射 + V2 header 的 bitfield 分配 + body offset/align 设计”**再写到更像 PR checklist 的粒度，我也可以直接按你 repo 的 `pfss_backend_gpu.cu / pfss_kernels.cu` 现有风格给出更细的骨架（但不需要你再补充信息也能写出一版默认参数集）。

[1]: https://cris.bgu.ac.il/en/publications/improved-constructions-for-distributed-multi-point-functions-2/ "
        Improved Constructions for Distributed Multi-Point Functions
      \-  Ben-Gurion University Research Portal"
[2]: https://git-crysp.uwaterloo.ca/iang/prac/src/main/cdpf.hpp "https://git-crysp.uwaterloo.ca/iang/prac/src/main/cdpf.hpp"
