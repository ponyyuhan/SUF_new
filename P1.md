Below is a *concrete, implementable* “Route **B1**” that upgrades your current **SIL1 IntervalLUT (DCF/StepDCF + per-level vector payload)** into a **SIL2-style IntervalLUT** where the **vector payload no longer scales with `in_bits`**, and evaluation is structured to be **single / near-single traversal** on GPU.

I’m going to define Route **B1** precisely as:

> **B1 = “True IntervalLUT (SIL2)” implemented as a CDPF / multi-point programmable-DPF style key**, where
> **key bytes** scale like **O(in_bits·λ + intervals·out_words)** (plus small overhead),
> and the GPU eval is **one traversal per element** (plus small per-interval work), **not** `(intervals-1)×DCF_eval`.

This is the path that fixes the core mismatch you highlighted: *your current IntervalLUT is still SIL1 (vector DCF), so preprocessing blows up even when per-element masks = 1*.

---

## 1) What SIL2 must achieve in your codebase

### 1.1 Target functionality (same semantics as today)

Given opened `u = x + r` (mod 2^k), and secret-shifted cutpoints `b_i = c_i + r`, you want:

* intervals: `I0 = (-∞, b1)`, `I1 = [b1, b2)`, …, `I_{m-1} = [b_{m-1}, +∞)`
* payload vectors: `P[0..m-1]`, each is `out_words` words (u64)
* output: `P[idx(u)]` as **additive shares** (ring Z2^64, wordwise)

### 1.2 Why SIL1 explodes

Your current secure GPU IntervalLUT does:

* For each boundary `b_i`, evaluate a **vector-output DCF** (StepDCF/DCF)
* Vector-output DCF needs `v_cw` at every level → key bytes `~ in_bits × out_words` per boundary
* Total per element `~ (intervals-1) × in_bits × out_words` words → catastrophic.

So SIL2 must:

* **keep boundary-hiding** (no plaintext thresholds),
* keep **non-interactive eval** (no Beaver-mux explosion),
* but move vector payload off “per-level v_cw”.

---

## 2) Route B1 design idea: delta-encoding + programmable / multi-point DPF

### 2.1 Delta encoding (mandatory)

Rewrite payloads as base + deltas:

* `D[0] = P[0]`
* `D[i] = P[i] - P[i-1]` for i=1..m-1

Then:

* `P[idx(u)] = D[0] + Σ_{i=1..m-1} D[i] · 1[u ≥ b_i]`

So IntervalLUT reduces to:

* base vector + sum of *(interval step predicates)* times deltas.

**This is the standard shape needed for SIL2**: the only thing that changes per interval is `D[i]` (an `out_words` vector), not per-level correction.

### 2.2 What B1 changes cryptographically

Instead of “(intervals-1) independent vector-DCF”, B1 uses **one shared tree expansion** and “programs” multiple jump points.

You can think of it as:

* One **global tree** of depth `in_bits`, with per-level correction words like a DPF/DCF (size `O(in_bits·λ)`).
* Plus a compact set of **programming records** (one per boundary), each record contributes the delta vector `D[i]` at its boundary in a way that evaluation accumulates the right deltas without storing `v_cw` at every level.

This is exactly the kind of “offline reusable + small per-point programming” idea described by *programmable DPFs*: a reusable base plus small “online programs” for many points. ([Ben-Gurion University Research Portal][1])

If you prefer an existing engineering reference point: Google’s open-source DPF codebase is an example of how people structure DPF-like keys with hierarchical / incremental evaluation and clean APIs. ([GitHub][2])

---

## 3) B1 key format in **your** code (fits your existing header style)

You already have:

* `SecureIntervalLutHeader` with `magic="SIL1"` today
* and you’ve mentioned a reserved `SIL2` idea.

### 3.1 Minimal header evolution without breaking alignment

Keep the struct size the same (32 bytes) but reinterpret reserved fields when `magic="SIL2"`:

* `dcf_key_bytes` = **0** for SIL2
* reuse reserved fields as:

    * `dpf_key_bytes` (u32)
    * `payload_bytes` (u32)
    * `corr_bytes` (u32)
    * `flags` (u32)

So layout becomes:

```
[SIL2 header 32B]
[core_bytes = dpf_key_bytes]           // shared tree: O(in_bits·λ)
[prog_records bytes = corr_bytes]      // per-boundary programming records: O((m-1)·λ)
[payload_table bytes = payload_bytes]  // D[0..m-1], each out_words*u64
```

### 3.2 What each section contains

#### (A) `core` (shared tree)

Contains per-party:

* root seed(s)
* per-level correction words needed for the traversal (like your DPF/DCF keys do)

Size target: `O(in_bits * 16B)` (plus small bits).

#### (B) `prog_records` (one per boundary)

For each boundary `b_i` you store:

* a small record that “programs” the jump at that point

Size target: `O(1) blocks` per boundary (e.g., 16–48 bytes), **not** `out_words*in_bits`.

#### (C) `payload_table`

Store deltas:

* `D[0..m-1]` in additive shares (each party holds its share)

Size: `m * out_words * 8 bytes`, which is exactly what you *want*.

---

## 4) B1 evaluation algorithm on GPU

### 4.1 High-level eval logic

For each element `u`:

1. Initialize accumulator `acc = D[0]` (vector add)
2. Traverse the shared tree **once** using `u` bits:

    * maintain a compact state (seeds + control bits)
3. While traversing, the state determines which programmed “jumps” apply
4. Add the corresponding delta vectors `D[i]` into `acc`
5. Output `acc`

The core point:

* You do **one traversal per element** (depth `in_bits`)
* You do **not** loop `for i in intervals-1: dcf_eval(i)` as SIL1 does.

### 4.2 GPU mapping (warp-friendly)

You already have a warp-per-element pattern in `interval_lut_sigma_dcf_kernel_keyed_warp`:

* lane 0 handles the element and loops boundaries (bad for SIL1)

For SIL2, you want:

* lane 0 performs the traversal
* other lanes help process programming records (e.g., in chunks of 32)

Pseudo-structure:

```cpp
warp handles element e
u = xs[e]

acc = D0_share  // out_words

// 1) shared traversal: O(in_bits)
state = init(core_key)
for level in 0..in_bits-1:
  state = step(state, bit(u, level))
  // state exposes a small selector / token for which jump group to apply

// 2) apply programmed jumps: O(intervals/32) with lanes in parallel
for group in groups_of_32(program_records):
  lane processes one record
  if record triggers under final state/u:
      acc += D[i]   // vector add

store acc
```

The exact “record triggers” condition depends on the programmable DP F construction you pick (next section), but the GPU parallelization pattern is stable.

---

## 5) The core crypto choice inside Route B1

B1 is **not** “just rewrite some loops”; you must pick one of these constructions for the “program records”.

I’ll give you the two most realistic options (both satisfy your “no plaintext thresholds” and “key shape independent of masks”).

### Option B1.1: Integrate an existing programmable / multi-point DPF construction

This is the most direct “true SIL2” route:

* Base offline key: one tree
* Each boundary is programmed by a small online record
* Evaluation is one traversal + applying records

This matches the programmable DPF concept: reusable offline key + cheap per-point online programming. ([Ben-Gurion University Research Portal][1])

**What you implement:**

* `pdpf_keygen(base_key, {(b_i, i)})` → per party
* `pdpf_eval(base_key, prog_records, u)` → returns which deltas to add

**Pros**

* Best asymptotic key shrink vs SIL1
* Evaluation near single traversal

**Cons**

* You must implement the PD-PF spec (or port a reference implementation)
* More cryptographic engineering work, but it’s contained and testable

---

### Option B1.2: “Multi-cut shared expansion” built in-house using a trie-of-points + per-level packing

If you don’t want a full PD-PF, you can implement a **multi-point DPF** in the “shared expansion” style:

* Build a structure that shares GGM expansions among many points
* Store correction words that hide where points are
* Evaluation does one path, plus small bookkeeping

This is essentially “DMPF/CDPF” engineering:

* you pay **O(in_bits·λ)** once,
* and **O((m-1)·λ)** for programming,
* but not `out_words·in_bits`.

**Pros**

* No external assumptions beyond PRG you already use
* Easier to tailor to GPU (warp-native)

**Cons**

* You still need to design and validate the multi-point key structure
* More room for subtle bugs than B1.1

---

## 6) How Route B1 lands into your repo (concrete file-level plan)

### 6.1 Code touchpoints

1. **Key format**

* `include/proto/secure_pfss_key_formats.hpp`

    * Add `magic="SIL2"`, version=2
    * Reinterpret reserved fields as described

2. **Secure backend keygen**

* `cuda/pfss_backend_gpu.cu`

    * In `SecureGpuPfssBackend::gen_interval_lut(...)`:

        * add a branch:

            * if `interval_lut_version == 2` → call `gen_interval_lut_v2_sil2(...)`
            * else keep SIL1 path

3. **Secure backend eval dispatch**

* `cuda/pfss_backend_gpu.cu`

    * In `eval_interval_lut_many_device(...)`:

        * dispatch on header.magic `"SIL2"`

4. **GPU kernel**

* `cuda/pfss_kernels.cu`

    * Add `interval_lut_sil2_kernel_warp`:

        * warp-per-element
        * one traversal
        * record-parallel jump accumulation

5. **CPU reference + tests**

* Add a CPU reference implementation for SIL2 eval:

    * easiest: run the same “program record” logic on CPU and compare against plaintext interval LUT for random tests

### 6.2 Feature gating

Add an env var similar to your other toggles:

* `SUF_SECURE_GPU_INTERVAL_LUT_VERSION=2`

Default to SIL1 until tests pass.

---

## 7) Validation checklist (so B1 doesn’t silently break security/perf)

### Correctness tests (must-have)

For random seeds and random `r`:

* generate cutpoints in x-domain
* shift to hatx-domain via `+r`
* generate random payload vectors `P[i]`
* run:

    * plaintext interval lookup on `x` (or equivalently on `u` with shifted bounds)
    * SIL2 keygen + two-party eval and recombine shares
* assert equality for many random cases
* include edge cases:

    * `u` exactly equals a boundary
    * wrap-around near 0 / 2^k-1 if your domain is modular

### Security sanity checks (engineering-level)

* Ensure **no plaintext cutpoints** stored in keys (grep for them, or check they never appear in serialization).
* Ensure key blob size depends only on `(in_bits, out_words, intervals)` and not on actual sampled `r`.

### Performance instrumentation

Add counters similar to your current:

* key bytes per SIL2 interval lut key
* kernel time for interval lut eval
* number of PRG expansions per element

---

## 8) What you should expect if B1 is implemented correctly

### Preprocessing material

Your IntervalLUT contribution should drop from roughly:

* **SIL1**: `(intervals-1) * in_bits * out_words * 8`  (dominant)
  to
* **SIL2**: `in_bits * O(λ)` + `(intervals * out_words * 8)` + `(intervals * O(λ))`

That’s the structural win you need to get out of the “per-element masks=1 but still huge” trap.

### Runtime

* Eval becomes “one traversal” rather than `(intervals-1) traversals`
* GPU warp structure becomes **compute-bound** rather than key-load / loop-bound

---

## 9) If you want the next step (without asking you to clarify anything)

If you confirm (or just proceed) that “B1 = implement SIL2 / true IntervalLUT”, the next thing I would do is:

* write the exact byte layout for `prog_record` and `core` in terms of blocks/words,
* map it to a concrete “programming DPF” construction choice (B1.1 vs B1.2),
* and then give you **kernel pseudocode at the same level of detail as your existing `drelu1_kernel_keyed_warp` / `spc2 dpf_prefix_sum_kernel` patterns**, including:

    * lane responsibilities
    * shared-memory staging
    * coalesced loads
    * offsets and alignment

For now, the above is the full “Route B1” implementation blueprint: it’s the smallest path that actually turns IntervalLUT into a *true* SIL2-style template and removes the `out_words × in_bits` factor that’s currently killing your preprocessing material.

[1]: https://cris.bgu.ac.il/en/publications/programmable-distributed-point-functions/ "
        Programmable Distributed Point Functions
      \-  Ben-Gurion University Research Portal"
[2]: https://github.com/google/distributed_point_functions "GitHub - google/distributed_point_functions: An Implementation of Incremental Distributed Point Functions in C++"
